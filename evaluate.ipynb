{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ed181f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>load_the_dataset</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process_store_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>find_unique_values</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_sales</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>check_missing_values</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sales_distribution</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>top_customer_segment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>regional_purchasing_behavior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>high_spending_regions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>popular_product_categories</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>avg_quantity_per_transaction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>quantity_sales_relationship</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>category_quantity_sales_trends</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>highest_profit_segments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clean_and_calculate_shipping_time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>calculate_discounted_price</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>calculate_revenue_per_day</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>identify_most_discounted_products</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>analyze_revenue_efficiency</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>anova_sales_by_category</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ttest_sales_by_segment</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>apply_outlier_treatment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>compute_correlations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>drop_var1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>normalize_numeric_columns</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>one_hot_encode</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>total_result</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Function  Score\n",
       "0                    load_the_dataset      2\n",
       "1                  process_store_data      1\n",
       "2                  find_unique_values      1\n",
       "3                         total_sales      1\n",
       "4                check_missing_values      1\n",
       "5                  sales_distribution      1\n",
       "6                top_customer_segment      1\n",
       "7        regional_purchasing_behavior      1\n",
       "8               high_spending_regions      1\n",
       "9          popular_product_categories      1\n",
       "10       avg_quantity_per_transaction      1\n",
       "11        quantity_sales_relationship      1\n",
       "12     category_quantity_sales_trends      1\n",
       "13            highest_profit_segments      1\n",
       "14  clean_and_calculate_shipping_time      1\n",
       "15         calculate_discounted_price      1\n",
       "16          calculate_revenue_per_day      1\n",
       "17  identify_most_discounted_products      2\n",
       "18         analyze_revenue_efficiency      2\n",
       "19            anova_sales_by_category      2\n",
       "20             ttest_sales_by_segment      2\n",
       "21            apply_outlier_treatment      1\n",
       "22               compute_correlations      1\n",
       "23                          drop_var1      1\n",
       "24          normalize_numeric_columns      1\n",
       "25                     one_hot_encode      2\n",
       "26                       total_result     32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Final Eval Score ####\n",
    "import nbformat\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "problem_notebook_path = \"/Users/rakeshdevarakonda/Documents/Auto_Eval/problem/problem.ipynb\"\n",
    "solution_notebook_path = \"/Users/rakeshdevarakonda/Documents/Auto_Eval/solution/Solution.ipynb\"\n",
    "\n",
    "# Task weightage list\n",
    "task_weightage = {\n",
    "    \"load_the_dataset\": 2,\n",
    "    \"process_store_data\": 1,\n",
    "    \"find_unique_values\": 1,\n",
    "    \"total_sales\": 1,\n",
    "    \"check_missing_values\": 1,\n",
    "    \"sales_distribution\": 1,\n",
    "    \"top_customer_segment\": 1,\n",
    "    \"regional_purchasing_behavior\": 1,\n",
    "    \"high_spending_regions\": 1,\n",
    "    \"popular_product_categories\": 1,\n",
    "    \"avg_quantity_per_transaction\": 1,\n",
    "    \"quantity_sales_relationship\": 1,\n",
    "    \"category_quantity_sales_trends\": 1,\n",
    "    \"highest_profit_segments\": 1,\n",
    "    \"clean_and_calculate_shipping_time\": 1,\n",
    "    \"calculate_discounted_price\": 1,\n",
    "    \"calculate_revenue_per_day\": 1,\n",
    "    \"identify_most_discounted_products\": 2,\n",
    "    \"analyze_revenue_efficiency\": 2,\n",
    "    \"anova_sales_by_category\": 2,\n",
    "    \"ttest_sales_by_segment\": 2,\n",
    "    \"treat_outliers_iqr\": 1,\n",
    "    \"apply_outlier_treatment\": 1,\n",
    "    \"compute_correlations\": 1,\n",
    "    \"drop_var1\": 1,\n",
    "    \"normalize_numeric_columns\": 1,\n",
    "    \"one_hot_encode\": 2\n",
    "}\n",
    "\n",
    "def extract_function_outputs_fixed(notebook_path, valid_functions):\n",
    "    \"\"\"\n",
    "    Extracts function outputs from a Jupyter notebook, filtering only those\n",
    "    in the valid_functions list (task_weightage keys).\n",
    "    \n",
    "    Returns a DataFrame containing function names and corresponding outputs.\n",
    "    \"\"\"\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    function_outputs = []\n",
    "    current_function = None\n",
    "\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code':\n",
    "            cell_outputs = []\n",
    "\n",
    "            # Extract function name from the code cell\n",
    "            lines = cell.source.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                if line.strip().startswith(\"def \"):\n",
    "                    function_name = line.split(\"(\")[0].replace(\"def \", \"\").strip()\n",
    "                    if function_name in valid_functions:\n",
    "                        current_function = function_name\n",
    "                    else:\n",
    "                        current_function = None\n",
    "                    break\n",
    "            \n",
    "            # Extract outputs if function is valid\n",
    "            if current_function:\n",
    "                for output in cell.get('outputs', []):\n",
    "                    if 'text' in output:\n",
    "                        cell_outputs.append(output['text'].strip())\n",
    "                    elif 'data' in output and 'text/plain' in output['data']:\n",
    "                        cell_outputs.append(output['data']['text/plain'].strip())\n",
    "                    elif 'traceback' in output:\n",
    "                        cell_outputs.append(\"ERROR: \" + \"\\n\".join(output['traceback']))\n",
    "\n",
    "                # Store function name and outputs if available\n",
    "                if cell_outputs:\n",
    "                    formatted_output = \" \".join(cell_outputs).replace(\"\\n\", \" \").strip()\n",
    "                    function_outputs.append({\"Function\": current_function, \"Output\": formatted_output})\n",
    "\n",
    "    return pd.DataFrame(function_outputs)\n",
    "\n",
    "def compare_outputs(problem_df, solution_df, task_weightage):\n",
    "    \"\"\"\n",
    "    Compares function outputs from problem and solution dataframes.\n",
    "    Assigns a score based on task weightage if outputs match, otherwise assigns 0.\n",
    "    \n",
    "    Returns a dataframe with function names and scores.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    # Convert solution dataframe to dictionary for quick lookup\n",
    "    solution_dict = dict(zip(solution_df[\"Function\"], solution_df[\"Output\"]))\n",
    "\n",
    "    for _, row in problem_df.iterrows():\n",
    "        function_name = row[\"Function\"]\n",
    "        problem_output = row[\"Output\"]\n",
    "        solution_output = solution_dict.get(function_name, None)\n",
    "\n",
    "        # Check if the outputs match and assign score accordingly\n",
    "        if solution_output and problem_output.strip() == solution_output.strip():\n",
    "            score = task_weightage.get(function_name, 0)\n",
    "        else:\n",
    "            score = 0\n",
    "\n",
    "        scores.append({\"Function\": function_name, \"Score\": score})\n",
    "\n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "# Extract function outputs, considering only those present in task_weightage\n",
    "problem_file = extract_function_outputs_fixed(problem_notebook_path, task_weightage.keys())\n",
    "solution_file = extract_function_outputs_fixed(solution_notebook_path, task_weightage.keys())\n",
    "\n",
    "# Compare outputs and calculate scores\n",
    "score_df = compare_outputs(problem_file, solution_file, task_weightage)\n",
    "#score_df\n",
    "\n",
    "# Calculating the total sum of scores\n",
    "total_score = score_df[\"Score\"].sum()\n",
    "\n",
    "# Appending the total score row\n",
    "total_row = pd.DataFrame({\"Function\": [\"total_result\"], \"Score\": [total_score]})\n",
    "score_df = pd.concat([score_df, total_row], ignore_index=True)\n",
    "score_df\n",
    "#score_df.to_csv('/Users/rakeshdevarakonda/Documents/Auto_Eval/score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ba9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
